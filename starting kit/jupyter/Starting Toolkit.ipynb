{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiments analysis challenge on movie review\n",
    "## Designed by : Il faut sauver les datas, Ryan !\n",
    "\n",
    "\n",
    "    Boosz Paul \n",
    "    Estrade Victor \n",
    "    Gensollen Thibaut \n",
    "    Rais Hadjer \n",
    "    Sakly Sami "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The data set is composed of an equilibred number of positive /negative movie review. It will be on the form of 3 different CSV files. \n",
    "\n",
    "- Train.csv contains 10k examples with 3 columns : id, label, review\n",
    "- Test_public.csv 5k examples with 3 columns : id, label, review\n",
    "- Test_private.csv contains 10k examples with only 2 columns : id, review\n",
    "\n",
    "The goal is to predict the <code>predicted_label</code> column. The prediction quality is measured by the precision metrics. \n",
    "\n",
    "Results should be a txt file or csv file with 1 column : the predicted_class {0,1} as shown in this toolkit.\n",
    "You have to keep the original order of the datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data and load it in pandas\n",
    "\n",
    "The first things to do is to dawload all the data at the website : \n",
    "https://competitions.codalab.org/competitions/8131#learn_the_details-description\n",
    "\n",
    "To rename them (remove the keys 'datasets_None_0b3a301a-be2e-4f21-8be9-dfa5c56439c4') to their original names:\n",
    "\n",
    "- train.data\n",
    "- valid.data\n",
    "- test.data\n",
    "- train_preprocessed.data\n",
    "- valid_preprocessed.data\n",
    "- test_preprocessed.data\n",
    "\n",
    "and place them in a 'data/' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 30 days\n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 30 days\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Original Data / contains data + labels 10 k \n",
    "train = pd.read_csv(\"../data/train.data\")#.drop('id',axis =1 )\n",
    "# Your validation data / we provide also a validation dataset, contains only data : 5k\n",
    "valid = pd.read_csv(\"../data/valid.data\")#.drop('id',axis =1 )\n",
    "# final submission\n",
    "test = pd.read_csv(\"../data/test.data\")#.drop('id',axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 10000\n",
      "public test size 5000\n",
      "private test size 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"train size\", len(train))\n",
    "print(\"public test size\", len(valid))\n",
    "print(\"private test size\",len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw text : \n",
      " Yes, it's another great magical Muppet's movie and I adore them all; the characters, the movies, the TV show episodes (it's the best comedy or musical TV show ever) and all the artists behind it. But here they did such a rare fatal mistake and I'm surely talking about the weird ending !! <br /><br />I think it's very dangerous to involve that much, in American drama, and end a love affair by marriage !! We, as all the poor viewers, feel so free or maybe happy for the absence of its annoyance, peevishness and misery ! So we all enjoy these stories which gather 2 cute heroes as couple in love without the legitimate bond like Mickey Mouse and Minnie, Superman and Lois Lane, Dick Tracy and Tess, etc. So with all of the previous couples and their likes I bet that you feel safe, serenity and peace. Therefore when you look at what the makers of this movie had already done you'll be as mad as me !<br /><br />They made the weak miserable creature (Kermit) marry his daily nightmare, the most vexatious female ever (Miss Piggy) ! This is a historical change by the measures of the American entertainment's industry ! And it was pretty normal to have a negative impact upon the audience whom just refused to bless or believe or being satisfied with that sudden marriage (even the pathetic frog didn't have the time or the proper opportunity to think or to decide anything !). Therefore no wonder at all when you know that this movie is the most failure one in their cinematic serious, grossing only 25 millions vis-à-vis 65 millions earned by the first one (The Muppet Movie  1979) five years earlier !!<br /><br />Simply in this movie they took Manhattan, and my rest too !\n",
      "label : 1\n"
     ]
    }
   ],
   "source": [
    "# creating arrays from pandas dataframe\n",
    "X_train = train['review'].values\n",
    "y_train = train['label'].values\n",
    "X_valid = valid['review'].values\n",
    "X_test = test['review'].values\n",
    "print(\"raw text : \\n\", X_train[0])\n",
    "print(\"label :\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainning and testing the model with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# creating random forest classifier \n",
    "rfst = RandomForestClassifier(n_estimators = 100)\n",
    "# TfIdf Vectorizer with default parameters \n",
    "myTfidfVect = TfidfVectorizer(stop_words='english', max_features=30000)\n",
    "X_train_transformed = myTfidfVect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8373 % +/- 0.00580172388174 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rfst, X_train_transformed, y_train,\n",
    "               scoring='accuracy', cv=5)\n",
    "print('accuracy :', np.mean(scores), '% +/-', np.std(scores), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Trainning the model on the complete trainning dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trainned.\n"
     ]
    }
   ],
   "source": [
    "rfst.fit(X_train_transformed, y_train)\n",
    "print('Model trainned.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_transformed = myTfidfVect.transform(X_valid)\n",
    "X_test_transformed = myTfidfVect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_valid = rfst.predict(X_valid_transformed)\n",
    "prediction_test = rfst.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "0           0\n",
       "1           0\n",
       "2           1\n",
       "3           0\n",
       "4           0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(prediction_valid[:5], columns=['prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir(os.path.join(os.getcwd(),'results')):\n",
    "    os.mkdir(os.path.join(os.getcwd(),'results'))\n",
    "np.savetxt('results/valid.predict', prediction_valid, fmt='%d')\n",
    "np.savetxt('results/test.predict', prediction_test, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last operation is to zip the results.\n",
    "Zip only the 'valid.predict' and the 'test.predict' files **not the results directory** !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
